{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "import os\n",
    "import numpy\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_NAME = \"./imageValidate/yayoi_first_087.png\"\n",
    "#IMG_NAME = \"./imageValidate2/comic.bmp\"\n",
    "IMG_NAME = \"./imageValidate2/butterfly_GT.bmp\"\n",
    "\n",
    "IMG_OPENCV_NAME = \"opencv.png\"\n",
    "IMG_DNN_NAME = \"srcnn.png\"\n",
    "\n",
    "INTERPOLATION = cv2.INTER_CUBIC\n",
    "SCALE = 2\n",
    "SIZE_CONV = 6\n",
    "\n",
    "FILEPATH_NETWORK = \"./model/\"\n",
    "FILENAME_NETWORK = \"yayoi_srcnn_935_2x_network.json\"\n",
    "FILEPATH_WEIGHT = \"./model/\"\n",
    "FILENAME_WEIGHT = \"yayoi_srcnn_935_2x_weight.h5\"\n",
    "\n",
    "PSNR = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV interpolation methods\n",
    "INTER_NEAREST - a nearest-neighbor interpolation<br>\n",
    "INTER_LINEAR - a bilinear interpolation (used by default)<br>\n",
    "INTER_AREA - resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moireâ€™-free results. But when the image is zoomed, it is similar to the INTER_NEAREST method.<br>\n",
    "INTER_CUBIC - a bicubic interpolation over 4x4 pixel neighborhood<br>\n",
    "INTER_LANCZOS4 - a Lanczos interpolation over 8x8 pixel neighborhood<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, None, None, 128)   10496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    73792     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 1)     1601      \n",
      "=================================================================\n",
      "Total params: 85,889\n",
      "Trainable params: 85,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "json_file = open(FILEPATH_NETWORK + FILENAME_NETWORK, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(FILEPATH_WEIGHT + FILENAME_WEIGHT)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick1 = cv2.getTickCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate OpenCV resized image for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
    "shape = img.shape\n",
    "\n",
    "if PSNR:\n",
    "    img = cv2.resize(img, (int(shape[1] / SCALE), int(shape[0] / SCALE)), INTERPOLATION)\n",
    "    img = cv2.resize(img, (shape[1], shape[0]), INTERPOLATION)\n",
    "else:\n",
    "    img = cv2.resize(img, (shape[1] * SCALE, shape[0] * SCALE), INTERPOLATION)\n",
    "\n",
    "cv2.imwrite(IMG_OPENCV_NAME, img, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate super resolution image by SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "shape = img.shape\n",
    "\n",
    "if PSNR:\n",
    "    imgY = cv2.resize(img[:, :, 0], (int(shape[1] / SCALE), int(shape[0] / SCALE)), INTERPOLATION)\n",
    "    imgY = cv2.resize(imgY, (shape[1], shape[0]), cv2.INTER_CUBIC)\n",
    "    img[:, :, 0] = imgY\n",
    "else:\n",
    "    imgY = cv2.resize(img[:, :, 0], (int(shape[1] * SCALE), int(shape[0] * SCALE)), INTERPOLATION)\n",
    "    img[:, :, 0] = imgY\n",
    "\n",
    "tensorY = numpy.zeros((1, shape[0], shape[1], 1), dtype=float)\n",
    "tensorY[0, :, :, 0] = imgY.astype(float) / 255.\n",
    "\n",
    "tensorOutput = model.predict(tensorY, batch_size=1) * 255.\n",
    "tensorOutput[tensorOutput[:] > 255] = 255\n",
    "tensorOutput[tensorOutput[:] < 0] = 0\n",
    "tensorOutput = tensorOutput.astype(numpy.uint8)\n",
    "\n",
    "img[SIZE_CONV: -SIZE_CONV, SIZE_CONV: -SIZE_CONV, 0] = tensorOutput[0, :, :, 0]\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
    "cv2.imwrite(IMG_DNN_NAME, img, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSNR calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv:\n",
      "24.782076560337416\n",
      "srcnn:\n",
      "29.741241339454547\n"
     ]
    }
   ],
   "source": [
    "im1 = cv2.imread(IMG_NAME, cv2.IMREAD_COLOR)\n",
    "im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "im2 = cv2.imread(IMG_OPENCV_NAME, cv2.IMREAD_COLOR)\n",
    "im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "im3 = cv2.imread(IMG_DNN_NAME, cv2.IMREAD_COLOR)\n",
    "im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "if PSNR:\n",
    "    print(\"opencv:\")\n",
    "    print(cv2.PSNR(im1, im2))\n",
    "    print(\"srcnn:\")\n",
    "    print(cv2.PSNR(im1, im3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pltShow = False\n",
    "\n",
    "if pltShow:    \n",
    "    plt.figure(num='comparison',figsize=(16,16))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('origin image')\n",
    "    plt.imshow(im1)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('OpenCV')\n",
    "    plt.imshow(im2)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"srcnn\")\n",
    "    plt.imshow(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference processed time: 997 ms\n"
     ]
    }
   ],
   "source": [
    "tick2 = cv2.getTickCount()\n",
    "tick = math.floor( ((tick2 - tick1) * 1000) / cv2.getTickFrequency())\n",
    "\n",
    "if tick >= 60000:\n",
    "    mins = math.floor(tick / 60000)\n",
    "    secs = math.floor((tick - mins * 60000) / 1000)\n",
    "    msec = tick - mins * 60000 - secs * 1000\n",
    "    print(\"Inference processed time: \" + str(mins) + \" mins \" + str(secs) + \" secs \" + str(msec) + \" ms\")\n",
    "elif tick >= 1000:\n",
    "    secs = math.floor(tick / 1000)\n",
    "    msec = tick - secs * 1000\n",
    "    print(\"Inference processed time: \" + str(secs) + \" secs \" + str(msec) + \" ms\")\n",
    "else:\n",
    "    print(\"Inference processed time: \" + str(tick) + \" ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasExport = False\n",
    "\n",
    "if kerasExport:\n",
    "    FILEPATH_MODEL = \"\"\n",
    "    FILENAME_MODEL = \"yayoi_srcnn.h5\"\n",
    "    \n",
    "    loaded_model.save(FILEPATH_MODEL + FILENAME_MODEL)\n",
    "    print(FILENAME_MODEL + \" save complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export tensorflow freeze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 6 variables.\n",
      "Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "pbExport = True\n",
    "\n",
    "if pbExport:\n",
    "    FILEPATH_PB = \"\"\n",
    "    FILENAME_PB = \"yayoi_srcnn.pb\"\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from keras import backend as K\n",
    "\n",
    "    frozen_graph = freeze_session(K.get_session(),output_names=[out.op.name for out in model.outputs])\n",
    "    tf.train.write_graph(frozen_graph, FILEPATH_PB, FILENAME_PB, as_text=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
