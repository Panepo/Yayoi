{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "from utility.h5data import h5DataWrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FORMAT = \".png\"\n",
    "DATAPATH_TRAIN = \"./imageTrain/\"\n",
    "DATAPATH_VALIDATE = \"./imageValidate/\"\n",
    "\n",
    "RANDOM_CROP = 30\n",
    "SIZE_PATCH = 32\n",
    "\n",
    "SCALE = 4\n",
    "INTERPOLATION = cv2.INTER_CUBIC\n",
    "\n",
    "FILENAME_TRAIN = \"yayoi_waifu2x_dataTrain_\" + str(SCALE) + \"_\"+ str(SIZE_PATCH) + \".h5\"\n",
    "FILENAME_VALIDATE = \"yayoi_waifu2x_dataValidate_\" + str(SCALE) + \"_\"+ str(SIZE_PATCH) + \".h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV interpolation methods\n",
    "INTER_NEAREST - a nearest-neighbor interpolation<br>\n",
    "INTER_LINEAR - a bilinear interpolation (used by default)<br>\n",
    "INTER_AREA - resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moireâ€™-free results. But when the image is zoomed, it is similar to the INTER_NEAREST method.<br>\n",
    "INTER_CUBIC - a bicubic interpolation over 4x4 pixel neighborhood<br>\n",
    "INTER_LANCZOS4 - a Lanczos interpolation over 8x8 pixel neighborhood<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = numpy.zeros((nums * RANDOM_CROP, 1, SIZE_PATCH, SIZE_PATCH, 3), dtype=numpy.double)\n",
    "    label = numpy.zeros((nums * RANDOM_CROP, 1, SIZE_PATCH, SIZE_PATCH, 3), dtype=numpy.double)\n",
    "\n",
    "    for i in range(nums):\n",
    "        if DATA_FORMAT in names[i]:\n",
    "            name = _path + names[i]\n",
    "\n",
    "            hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "            shape = hr_img.shape\n",
    "\n",
    "            lr_img = cv2.resize(hr_img, (int(shape[1] / SCALE), int(shape[0] / SCALE)), INTERPOLATION)\n",
    "            lr_img = cv2.resize(lr_img, (shape[1], shape[0]), INTERPOLATION)\n",
    "            \n",
    "            Points_x = numpy.random.randint(0, min(shape[0], shape[1]) - SIZE_PATCH, RANDOM_CROP)\n",
    "            Points_y = numpy.random.randint(0, min(shape[0], shape[1]) - SIZE_PATCH, RANDOM_CROP)\n",
    "\n",
    "            for j in range(RANDOM_CROP):\n",
    "                lr_patch = lr_img[Points_x[j]: Points_x[j] + SIZE_PATCH, Points_y[j]: Points_y[j] + SIZE_PATCH]\n",
    "                hr_patch = hr_img[Points_x[j]: Points_x[j] + SIZE_PATCH, Points_y[j]: Points_y[j] + SIZE_PATCH]\n",
    "\n",
    "                lr_patch = lr_patch.astype(float) / 255.\n",
    "                hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "                data[i * RANDOM_CROP + j, 0, :, :, :] = lr_patch\n",
    "                label[i * RANDOM_CROP + j, 0, :, :, :] = hr_patch\n",
    "                \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_STEP = 16\n",
    "BLOCK_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCropData(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(nums):\n",
    "        if DATA_FORMAT in names[i]:\n",
    "            name = _path + names[i]\n",
    "            hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "            shape = hr_img.shape\n",
    "\n",
    "            lr_img = cv2.resize(hr_img, (int(shape[1] / SCALE), int(shape[0] / SCALE)))\n",
    "            lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "            width_num = (shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP\n",
    "            height_num = (shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP\n",
    "            for k in range(int(width_num)):\n",
    "                for j in range(int(height_num)):\n",
    "                    x = k * BLOCK_STEP\n",
    "                    y = j * BLOCK_STEP\n",
    "                    hr_patch = hr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "                    lr_patch = lr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "\n",
    "                    lr_patch = lr_patch.astype(float) / 255.\n",
    "                    hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "                    data.append(lr_patch)\n",
    "                    label.append(hr_patch)\n",
    "\n",
    "    data = numpy.array(data, dtype=float)\n",
    "    label = numpy.array(label, dtype=float)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick1 = cv2.getTickCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yayoi_waifu2x_dataTrain_4_32.h5 generated\n",
      "yayoi_waifu2x_dataValidate_4_32.h5 generated\n"
     ]
    }
   ],
   "source": [
    "data, label = parseCropData(DATAPATH_TRAIN)\n",
    "h5DataWrite(data, label, FILENAME_TRAIN)\n",
    "print(FILENAME_TRAIN + \" generated\")\n",
    "data, label = parseData(DATAPATH_VALIDATE)\n",
    "h5DataWrite(data, label, FILENAME_VALIDATE)\n",
    "print(FILENAME_VALIDATE + \" generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed time: 711 ms\n"
     ]
    }
   ],
   "source": [
    "tick2 = cv2.getTickCount()\n",
    "tick = math.floor( ((tick2 - tick1) * 1000) / cv2.getTickFrequency())\n",
    "\n",
    "if tick >= 60000:\n",
    "    mins = math.floor(tick / 60000)\n",
    "    secs = math.floor((tick - mins * 60000) / 1000)\n",
    "    msec = tick - mins * 60000 - secs * 1000\n",
    "    print(\"processed time: \" + str(mins) + \" mins \" + str(secs) + \" secs \" + str(msec) + \" ms\")\n",
    "elif tick >= 1000:\n",
    "    secs = math.floor(tick / 1000)\n",
    "    msec = tick - secs * 1000\n",
    "    print(\"processed time: \" + str(secs) + \" secs \" + str(msec) + \" ms\")\n",
    "else:\n",
    "    print(\"processed time: \" + str(tick) + \" ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
